{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 6GB\n",
      "Dimensions:    (TIME: 43829, LONGITUDE: 135, LATITUDE: 129)\n",
      "Coordinates:\n",
      "  * TIME       (TIME) datetime64[ns] 351kB 1901-01-01 1901-01-02 ... 2023-12-31\n",
      "  * LONGITUDE  (LONGITUDE) float64 1kB 66.5 66.75 67.0 ... 99.5 99.75 100.0\n",
      "  * LATITUDE   (LATITUDE) float64 1kB 6.5 6.75 7.0 7.25 ... 38.0 38.25 38.5\n",
      "Data variables:\n",
      "    RAINFALL   (TIME, LATITUDE, LONGITUDE) float64 6GB ...\n",
      "Attributes:\n",
      "    CDI:          Climate Data Interface version 1.9.9rc1 (https://mpimet.mpg...\n",
      "    Conventions:  CF-1.6\n",
      "    history:      Tue Jan 28 12:23:18 2025: cdo mergetime RF25_ind1901_rfp25....\n",
      "    CDO:          Climate Data Operators version 1.9.9rc1 (https://mpimet.mpg...\n",
      "Latitude Range: 6.5 to 38.5\n",
      "Longitude Range: 66.5 to 100.0\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Load the NetCDF file\n",
    "dataset = xr.open_dataset(\"C:\\\\Users\\\\rasag\\Downloads\\IMDrainfall_1901-2023 - Copy\\IMDrainfall_1901-2023 - Copy.nc\")\n",
    "\n",
    "# View dataset variables\n",
    "print(dataset)\n",
    "\n",
    "# Print latitude and longitude ranges\n",
    "print(\"Latitude Range:\", dataset.LATITUDE.min().values, \"to\", dataset.LATITUDE.max().values)\n",
    "print(\"Longitude Range:\", dataset.LONGITUDE.min().values, \"to\", dataset.LONGITUDE.max().values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is empty! Trying reversed order...\n",
      "New Filtered Shape: (43829, 33, 33)\n",
      "<bound method Mapping.values of <xarray.Dataset> Size: 382MB\n",
      "Dimensions:    (TIME: 43829, LONGITUDE: 33, LATITUDE: 33)\n",
      "Coordinates:\n",
      "  * TIME       (TIME) datetime64[ns] 351kB 1901-01-01 1901-01-02 ... 2023-12-31\n",
      "  * LONGITUDE  (LONGITUDE) float64 264B 77.0 77.25 77.5 ... 84.5 84.75 85.0\n",
      "  * LATITUDE   (LATITUDE) float64 264B 12.0 12.25 12.5 12.75 ... 19.5 19.75 20.0\n",
      "Data variables:\n",
      "    RAINFALL   (TIME, LATITUDE, LONGITUDE) float64 382MB 0.0 0.0 0.0 ... 0.0 0.0\n",
      "Attributes:\n",
      "    CDI:          Climate Data Interface version 1.9.9rc1 (https://mpimet.mpg...\n",
      "    Conventions:  CF-1.6\n",
      "    history:      Tue Jan 28 12:23:18 2025: cdo mergetime RF25_ind1901_rfp25....\n",
      "    CDO:          Climate Data Operators version 1.9.9rc1 (https://mpimet.mpg...>\n",
      "(33,) (33,)\n"
     ]
    }
   ],
   "source": [
    "# Define Andhra Pradesh's latitude and longitude bounds\n",
    "import numpy as np\n",
    "lat_min, lat_max = 12.0, 20.0\n",
    "lon_min, lon_max = 77.0, 85.0\n",
    "# time = ap_data[\"time\"].values\n",
    "\n",
    "# Select the Andhra Pradesh region\n",
    "ap_data = dataset.sel(LATITUDE=slice(lat_max, lat_min), LONGITUDE=slice(lon_min, lon_max))\n",
    "\n",
    "if ap_data[\"RAINFALL\"].size == 0:\n",
    "    print(\"Dataset is empty! Trying reversed order...\")\n",
    "    # ap_data = dataset.sel(LATITUDE: slice(lat_max, lat_min), LONGITUDE: slice(lon_max, lon_min))\n",
    "    \n",
    "    ap_data = dataset.sel(LATITUDE=slice(lat_min, lat_max), LONGITUDE=slice(lon_min, lon_max))\n",
    "\n",
    "    print(\"New Filtered Shape:\", ap_data[\"RAINFALL\"].shape)\n",
    "\n",
    "# Extract latitude, longitude, and rainfall data\n",
    "lat = ap_data[\"LATITUDE\"].values\n",
    "lon = ap_data[\"LONGITUDE\"].values\n",
    "time = ap_data[\"TIME\"].values\n",
    "rainfall = ap_data[\"RAINFALL\"].values  # Change variable name if needed\n",
    "time_numeric = (time - np.datetime64(time[0])) / np.timedelta64(1, \"D\")\n",
    "print(ap_data.values)\n",
    "\n",
    "\n",
    "\n",
    "print(lat.shape, lon.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Latitudes: [ 6.5   6.75  7.    7.25  7.5   7.75  8.    8.25  8.5   8.75  9.    9.25\n",
      "  9.5   9.75 10.   10.25 10.5  10.75 11.   11.25 11.5  11.75 12.   12.25\n",
      " 12.5  12.75 13.   13.25 13.5  13.75 14.   14.25 14.5  14.75 15.   15.25\n",
      " 15.5  15.75 16.   16.25 16.5  16.75 17.   17.25 17.5  17.75 18.   18.25\n",
      " 18.5  18.75 19.   19.25 19.5  19.75 20.   20.25 20.5  20.75 21.   21.25\n",
      " 21.5  21.75 22.   22.25 22.5  22.75 23.   23.25 23.5  23.75 24.   24.25\n",
      " 24.5  24.75 25.   25.25 25.5  25.75 26.   26.25 26.5  26.75 27.   27.25\n",
      " 27.5  27.75 28.   28.25 28.5  28.75 29.   29.25 29.5  29.75 30.   30.25\n",
      " 30.5  30.75 31.   31.25 31.5  31.75 32.   32.25 32.5  32.75 33.   33.25\n",
      " 33.5  33.75 34.   34.25 34.5  34.75 35.   35.25 35.5  35.75 36.   36.25\n",
      " 36.5  36.75 37.   37.25 37.5  37.75 38.   38.25 38.5 ]\n",
      "Available Longitudes: [ 66.5   66.75  67.    67.25  67.5   67.75  68.    68.25  68.5   68.75\n",
      "  69.    69.25  69.5   69.75  70.    70.25  70.5   70.75  71.    71.25\n",
      "  71.5   71.75  72.    72.25  72.5   72.75  73.    73.25  73.5   73.75\n",
      "  74.    74.25  74.5   74.75  75.    75.25  75.5   75.75  76.    76.25\n",
      "  76.5   76.75  77.    77.25  77.5   77.75  78.    78.25  78.5   78.75\n",
      "  79.    79.25  79.5   79.75  80.    80.25  80.5   80.75  81.    81.25\n",
      "  81.5   81.75  82.    82.25  82.5   82.75  83.    83.25  83.5   83.75\n",
      "  84.    84.25  84.5   84.75  85.    85.25  85.5   85.75  86.    86.25\n",
      "  86.5   86.75  87.    87.25  87.5   87.75  88.    88.25  88.5   88.75\n",
      "  89.    89.25  89.5   89.75  90.    90.25  90.5   90.75  91.    91.25\n",
      "  91.5   91.75  92.    92.25  92.5   92.75  93.    93.25  93.5   93.75\n",
      "  94.    94.25  94.5   94.75  95.    95.25  95.5   95.75  96.    96.25\n",
      "  96.5   96.75  97.    97.25  97.5   97.75  98.    98.25  98.5   98.75\n",
      "  99.    99.25  99.5   99.75 100.  ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Available Latitudes:\", dataset.LATITUDE.values)\n",
    "print(\"Available Longitudes:\", dataset.LONGITUDE.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat.shape\n",
    "# lon.shape\n",
    "# rainfall.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 10  # Choose based on your data\n",
    "X, y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Data Shape: (47729781, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Flatten latitude, longitude, and time for LSTM\n",
    "# lat_grid, lon_grid = np.meshgrid(lat, lon, indexing='ij')\n",
    "lat_grid, lon_grid = np.meshgrid(lat, lon, indexing=\"ij\")\n",
    "\n",
    "lat_expanded = np.tile(lat_grid, (rainfall.shape[0], 1, 1))  # (time, 33, 33)\n",
    "lon_expanded = np.tile(lon_grid, (rainfall.shape[0], 1, 1))\n",
    "# data = np.column_stack((lat_grid.flatten(), lon_grid.flatten(), time_grid.flatten(), rainfall.flatten()))\n",
    "\n",
    "\n",
    "time_flat = np.repeat(time_numeric, 33 * 33)  # Convert time to numerical and repeat\n",
    "lat_flat = lat_expanded.flatten()\n",
    "lon_flat = lon_expanded.flatten()\n",
    "rainfall_flat = rainfall.flatten()\n",
    "\n",
    "assert lat_flat.shape == lon_flat.shape == rainfall_flat.shape == time_flat.shape, \"Shape mismatch after flattening!\"\n",
    "\n",
    "\n",
    "\n",
    "data = np.column_stack((time_flat, lat_flat, lon_flat, rainfall_flat))\n",
    "print(\"Final Data Shape:\", data.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data)\n",
    "\n",
    "# Reshape into LSTM format: (samples, timesteps, features)\n",
    "# timesteps = 10  # Define number of past time steps for prediction\n",
    "# X, y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 10  # Define number of past time steps for prediction\n",
    "X, y = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Input Shape: (47729771, 10, 4)\n",
      "LSTM Output Shape: (47729771,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_normalized) - timesteps):\n",
    "    X.append(data_normalized[i:i+timesteps])\n",
    "    y.append(data_normalized[i+timesteps][-1])  # Predict rainfall\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# Print final shapes\n",
    "print(\"LSTM Input Shape:\", X.shape)  # (samples, timesteps, features)\n",
    "print(\"LSTM Output Shape:\", y.shape)  # (samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Define LSTM model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[1;32m----> 8\u001b[0m     LSTM(\u001b[38;5;241m50\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39m(timesteps, \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m2\u001b[39m])),\n\u001b[0;32m      9\u001b[0m     LSTM(\u001b[38;5;241m50\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m#Dense(25, activation=\"relu\"),\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     Dense(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Predicting one value (temperature)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m ])\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Define LSTM model\n",
    "# model = Sequential([\n",
    "#     LSTM(50, return_sequences=True, input_shape=(timesteps, X.shape[2])),\n",
    "#     LSTM(50, return_sequences=False),\n",
    "#     #Dense(25, activation=\"relu\"),\n",
    "#     Dense(1)  # Predicting one value (temperature)\n",
    "# ])\n",
    "# #\n",
    "# model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "# model.summary()\n",
    "\n",
    "# # Train model\n",
    "# model.fit(X, y, epochs=50, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape before reshaping: (0,)\n",
      "y shape before reshaping: (0, 1)\n",
      "X shape after reshaping: (0,)\n",
      "y shape after reshaping: (0, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dataset is empty after preprocessing. Check filtering steps.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Check for empty dataset\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset is empty after preprocessing. Check filtering steps.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Check for NaNs\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(X)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(y)\u001b[38;5;241m.\u001b[39many():\n",
      "\u001b[1;31mValueError\u001b[0m: Dataset is empty after preprocessing. Check filtering steps."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "X = np.array(X, dtype=np.float32)  # Ensure numerical dtype\n",
    "y = np.array(y, dtype=np.float32)\n",
    "\n",
    "# Debugging input data\n",
    "print(f\"X shape before reshaping: {X.shape}\")\n",
    "print(f\"y shape before reshaping: {y.shape}\")\n",
    "\n",
    "# Ensure X has correct shape (samples, timesteps, features)\n",
    "timesteps = 10  # Number of past steps used for prediction\n",
    "num_features = X.shape[1] if len(X.shape) > 1 else 1  # Ensure features exist\n",
    "\n",
    "# Reshape if needed\n",
    "if len(X.shape) == 2:\n",
    "    X = X.reshape(-1, timesteps, num_features)\n",
    "\n",
    "# Ensure y is 2D (samples, 1)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "print(f\"X shape after reshaping: {X.shape}\")  # Should be (samples, timesteps, features)\n",
    "print(f\"y shape after reshaping: {y.shape}\")  # Should be (samples, 1)\n",
    "\n",
    "# Check for empty dataset\n",
    "if X.size == 0 or y.size == 0:\n",
    "    raise ValueError(\"Dataset is empty after preprocessing. Check filtering steps.\")\n",
    "\n",
    "# Check for NaNs\n",
    "if np.isnan(X).any() or np.isnan(y).any():\n",
    "    raise ValueError(\"Dataset contains NaN values. Please clean your data.\")\n",
    "\n",
    "# Define LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(timesteps, X.shape[2])),\n",
    "    LSTM(50, return_sequences=False),\n",
    "    Dense(1)  # Predicting one value (rainfall)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.summary()\n",
    "\n",
    "# Train model\n",
    "model.fit(X, y, epochs=50, batch_size=32, validation_split=0.2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
